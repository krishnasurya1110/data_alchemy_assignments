{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loan Approval Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from plotly.offline import plot\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>35000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>B</td>\n",
       "      <td>6000</td>\n",
       "      <td>11.49</td>\n",
       "      <td>0.17</td>\n",
       "      <td>N</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>56000</td>\n",
       "      <td>OWN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>C</td>\n",
       "      <td>4000</td>\n",
       "      <td>13.35</td>\n",
       "      <td>0.07</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>28800</td>\n",
       "      <td>OWN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>PERSONAL</td>\n",
       "      <td>A</td>\n",
       "      <td>6000</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0.21</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>70000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>14.0</td>\n",
       "      <td>VENTURE</td>\n",
       "      <td>B</td>\n",
       "      <td>12000</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.17</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>60000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>A</td>\n",
       "      <td>6000</td>\n",
       "      <td>6.92</td>\n",
       "      <td>0.10</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  person_age  person_income person_home_ownership  person_emp_length  \\\n",
       "0   0          37          35000                  RENT                0.0   \n",
       "1   1          22          56000                   OWN                6.0   \n",
       "2   2          29          28800                   OWN                8.0   \n",
       "3   3          30          70000                  RENT               14.0   \n",
       "4   4          22          60000                  RENT                2.0   \n",
       "\n",
       "  loan_intent loan_grade  loan_amnt  loan_int_rate  loan_percent_income  \\\n",
       "0   EDUCATION          B       6000          11.49                 0.17   \n",
       "1     MEDICAL          C       4000          13.35                 0.07   \n",
       "2    PERSONAL          A       6000           8.90                 0.21   \n",
       "3     VENTURE          B      12000          11.11                 0.17   \n",
       "4     MEDICAL          A       6000           6.92                 0.10   \n",
       "\n",
       "  cb_person_default_on_file  cb_person_cred_hist_length  loan_status  \n",
       "0                         N                          14            0  \n",
       "1                         N                           2            0  \n",
       "2                         N                          10            0  \n",
       "3                         N                           5            0  \n",
       "4                         N                           3            0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset and view it\n",
    "df = pd.read_csv('loan_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify data (adopted from EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop outliers\n",
    "df = df[df['person_age'] != 123]\n",
    "df = df[df['person_emp_length'] != 123]\n",
    "df = df[df['person_income'] <= 1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns due to their high correlation with other columns\n",
    "# loan_grade with interest rate (0.94)\n",
    "# person_age with credit_history_length (0.88)\n",
    "\n",
    "df.drop(['loan_grade', 'person_age'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map 'cb_person_default_on_file' (Y or N) to numerical values\n",
    "df['cb_person_default_on_file'] = df['cb_person_default_on_file'].map({'N': 0, 'Y': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after One-Hot Encoding:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_intent_DEBTCONSOLIDATION</th>\n",
       "      <th>loan_intent_EDUCATION</th>\n",
       "      <th>loan_intent_HOMEIMPROVEMENT</th>\n",
       "      <th>loan_intent_MEDICAL</th>\n",
       "      <th>loan_intent_PERSONAL</th>\n",
       "      <th>loan_intent_VENTURE</th>\n",
       "      <th>person_home_ownership_MORTGAGE</th>\n",
       "      <th>person_home_ownership_OTHER</th>\n",
       "      <th>person_home_ownership_OWN</th>\n",
       "      <th>person_home_ownership_RENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>35000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>11.49</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>56000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>13.35</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>28800</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>70000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12000</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>60000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>6.92</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  person_income  person_emp_length  loan_amnt  loan_int_rate  \\\n",
       "0   0          35000                0.0       6000          11.49   \n",
       "1   1          56000                6.0       4000          13.35   \n",
       "2   2          28800                8.0       6000           8.90   \n",
       "3   3          70000               14.0      12000          11.11   \n",
       "4   4          60000                2.0       6000           6.92   \n",
       "\n",
       "   loan_percent_income  cb_person_default_on_file  cb_person_cred_hist_length  \\\n",
       "0                 0.17                          0                          14   \n",
       "1                 0.07                          0                           2   \n",
       "2                 0.21                          0                          10   \n",
       "3                 0.17                          0                           5   \n",
       "4                 0.10                          0                           3   \n",
       "\n",
       "   loan_status  loan_intent_DEBTCONSOLIDATION  loan_intent_EDUCATION  \\\n",
       "0            0                            0.0                    1.0   \n",
       "1            0                            0.0                    0.0   \n",
       "2            0                            0.0                    0.0   \n",
       "3            0                            0.0                    0.0   \n",
       "4            0                            0.0                    0.0   \n",
       "\n",
       "   loan_intent_HOMEIMPROVEMENT  loan_intent_MEDICAL  loan_intent_PERSONAL  \\\n",
       "0                          0.0                  0.0                   0.0   \n",
       "1                          0.0                  1.0                   0.0   \n",
       "2                          0.0                  0.0                   1.0   \n",
       "3                          0.0                  0.0                   0.0   \n",
       "4                          0.0                  1.0                   0.0   \n",
       "\n",
       "   loan_intent_VENTURE  person_home_ownership_MORTGAGE  \\\n",
       "0                  0.0                             0.0   \n",
       "1                  0.0                             0.0   \n",
       "2                  0.0                             0.0   \n",
       "3                  1.0                             0.0   \n",
       "4                  0.0                             0.0   \n",
       "\n",
       "   person_home_ownership_OTHER  person_home_ownership_OWN  \\\n",
       "0                          0.0                        0.0   \n",
       "1                          0.0                        1.0   \n",
       "2                          0.0                        1.0   \n",
       "3                          0.0                        0.0   \n",
       "4                          0.0                        0.0   \n",
       "\n",
       "   person_home_ownership_RENT  \n",
       "0                         1.0  \n",
       "1                         0.0  \n",
       "2                         0.0  \n",
       "3                         1.0  \n",
       "4                         1.0  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# One-Hot Encoding for loan_intent and person_home_ownership\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False) # Keep all categories\n",
    "# one_hot_encoder = OneHotEncoder(sparse_output=False, drop='first')  # Drop first category to avoid multicollinearity\n",
    "columns_to_encode = ['loan_intent', 'person_home_ownership']\n",
    "encoded_features = one_hot_encoder.fit_transform(df[columns_to_encode])\n",
    "\n",
    "# Create a DataFrame for the encoded features\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=one_hot_encoder.get_feature_names_out(columns_to_encode), index=df.index)\n",
    "\n",
    "# Drop the original columns and join the encoded columns\n",
    "df_encoded = df.drop(columns=columns_to_encode).join(encoded_df)\n",
    "\n",
    "print(\"DataFrame after One-Hot Encoding:\")\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_encoded.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries for modeling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Initialize an empty DataFrame with the specified headers\n",
    "metrics_df = pd.DataFrame(columns=['Model/Metric', 'Accuracy', 'Precision', 'Recall', 'F1-score', 'AUC'])\n",
    "\n",
    "def prepare_data(data):\n",
    "    # Define features and target\n",
    "    X = data.drop(columns=['id', 'loan_status'])\n",
    "    y = data['loan_status']\n",
    "\n",
    "    # Split into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def evaluate_model(y_test, y_pred, y_pred_proba, model_name):\n",
    "    # Evaluate the model\n",
    "    accuracy = round(accuracy_score(y_test, y_pred), 2)\n",
    "    precision = round(precision_score(y_test, y_pred, average='binary'), 2)\n",
    "    recall = round(recall_score(y_test, y_pred, average='binary'), 2)\n",
    "    f1 = round(f1_score(y_test, y_pred, average='binary'), 2)\n",
    "    auc = round(roc_auc_score(y_test, y_pred_proba), 2)\n",
    "    \n",
    "    # print(f\"Accuracy: {accuracy}\")\n",
    "    # print(f\"Precision: {precision}\")\n",
    "    # print(f\"Recall: {recall}\")\n",
    "    # print(f\"F1-Score: {f1}\")\n",
    "    # print(f\"AUC: {auc}\")\n",
    "    # class_report = classification_report(y_test, y_pred)\n",
    "    # print(\"Classification Report:\")\n",
    "    # print(class_report)\n",
    "    # conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    # plt.figure(figsize=(4, 3))\n",
    "    # sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['0', '1'], yticklabels=['0', '1'])\n",
    "    # plt.xlabel('Predicted')\n",
    "    # plt.ylabel('True')\n",
    "    # plt.title('Confusion Matrix')\n",
    "    # plt.show()\n",
    "    \n",
    "    # Add metrics to the DataFrame\n",
    "    new_row = pd.DataFrame({\n",
    "        'Model/Metric': [model_name],\n",
    "        'Accuracy': [accuracy],\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'F1-score': [f1],\n",
    "        'AUC': [auc]\n",
    "    })\n",
    "    \n",
    "    global metrics_df\n",
    "    # Ensure new_row does not contain empty or all-NA columns\n",
    "    new_row = new_row.dropna(axis=1, how='all')\n",
    "    # Ensure metrics_df does not contain empty or all-NA columns before concatenation\n",
    "    metrics_df.dropna(axis=1, how='all', inplace=True)\n",
    "    # Append the new row to the DataFrame\n",
    "    metrics_df = pd.concat([metrics_df, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data(data)\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000, solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "evaluate_model(y_test, y_pred, y_pred_proba, 'Logistic Regression')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data(data)\n",
    "\n",
    "model = KNeighborsClassifier(\n",
    "    n_neighbors=5,      # Number of neighbors to use\n",
    "    weights='uniform',  # Use uniform weights\n",
    "    algorithm='auto',   # Choose algorithm used to compute nearest neighbors\n",
    "    n_jobs=-1           # Use all available processors\n",
    ")   \n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "evaluate_model(y_test, y_pred, y_pred_proba, 'KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADABoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data(data)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(max_depth=1, class_weight='balanced', random_state=42)\n",
    "\n",
    "model = AdaBoostClassifier(\n",
    "    estimator=base_estimator,\n",
    "    n_estimators=50,\n",
    "    algorithm='SAMME',\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "evaluate_model(y_test, y_pred, y_pred_proba, 'ADABoost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost with different weights\n",
    "\n",
    "def create_xgb_classifier(multiplication_factor=1.0):\n",
    "    X_train, X_test, y_train, y_test = prepare_data(data)\n",
    "    neg, pos = y_train.value_counts() # Calculate class imbalance ratio\n",
    "    scale_pos_weight = neg / pos   # Increase weight for the minority class\n",
    "    adjusted_weight = scale_pos_weight * multiplication_factor\n",
    "\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        # use_label_encoder=False,\n",
    "        scale_pos_weight=adjusted_weight,  # Balances classes by giving more weight to the minority class\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=200,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    evaluate_model(y_test, y_pred, y_pred_proba, f\"XGBoost (neg/pos * {multiplication_factor})\")\n",
    "\n",
    "create_xgb_classifier(1.0)\n",
    "# create_xgb_classifier(1.5)\n",
    "create_xgb_classifier(2.0)\n",
    "# create_xgb_classifier(2.5)\n",
    "create_xgb_classifier(3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Grid Search CV and class_weight = balanced\n",
    "X_train, X_test, y_train, y_test = prepare_data(data)\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=200,  # Number of trees\n",
    "    max_depth=5,      # Limit depth to prevent overfitting\n",
    "    random_state=42,\n",
    "    class_weight='balanced'  # Handles class imbalance\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "evaluate_model(y_test, y_pred, y_pred_proba, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'class_weight': 'balanced', 'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Best Parameters: {'class_weight': 'balanced', 'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best Parameters: {'class_weight': 'balanced_subsample', 'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search CV and class_weight = ['balanced', 'balanced_subsample']\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def create_rf_classifier_with_cv(cv=2):\n",
    "    X_train, X_test, y_train, y_test = prepare_data(data)\n",
    "    model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'class_weight': ['balanced', 'balanced_subsample']\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv, scoring='f1', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "    evaluate_model(y_test, y_pred, y_pred_proba, f\"Random Forest (cv = {cv})\")\n",
    "\n",
    "\n",
    "create_rf_classifier_with_cv(2)\n",
    "create_rf_classifier_with_cv(3)\n",
    "create_rf_classifier_with_cv(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Grid Search CV and class_weight = {0: 1, 1: neg / pos * multiplication_factor}\n",
    "\n",
    "def create_rf_classifier_with_weights(multiplication_factor=1.0):\n",
    "    X_train, X_test, y_train, y_test = prepare_data(data)\n",
    "\n",
    "    neg, pos = y_train.value_counts()\n",
    "    scale_pos_weight = neg / pos\n",
    "    class_weights = {0: 1, 1: scale_pos_weight * multiplication_factor}\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=200,  # Number of trees\n",
    "        max_depth=5,      # Limit depth to prevent overfitting\n",
    "        random_state=42,\n",
    "        class_weight=class_weights  # Custom weights to handle imbalance\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    evaluate_model(y_test, y_pred, y_pred_proba, f\"Random Forest (neg/pos * {multiplication_factor})\")\n",
    "\n",
    "create_rf_classifier_with_weights(1.0)\n",
    "create_rf_classifier_with_weights(2.0)\n",
    "create_rf_classifier_with_weights(3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'class_weight': {0: 1, 1: 6.023356789938614}, 'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best Parameters: {'class_weight': {0: 1, 1: 9.03503518490792}, 'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Best Parameters: {'class_weight': {0: 1, 1: 12.046713579877228}, 'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Best Parameters: {'class_weight': {0: 1, 1: 6.023356789938614}, 'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best Parameters: {'class_weight': {0: 1, 1: 9.03503518490792}, 'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Best Parameters: {'class_weight': {0: 1, 1: 12.046713579877228}, 'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search CV and class_weight = {0: 1, 1: neg / pos * multiplication_factor}\n",
    "\n",
    "def create_rf_classifier_with_cv_and_weights(cv=2, multiplication_factor=1.0):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = prepare_data(data)\n",
    "\n",
    "    neg, pos = y_train.value_counts()\n",
    "    scale_pos_weight = neg / pos\n",
    "    class_weights = {0: 1, 1: scale_pos_weight * multiplication_factor}\n",
    "\n",
    "    model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'class_weight': [class_weights]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv, scoring='f1', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "    evaluate_model(y_test, y_pred, y_pred_proba, f\"Random Forest (cv = {cv}) and (neg/pos * {multiplication_factor})\")\n",
    "\n",
    "create_rf_classifier_with_cv_and_weights(2, 1.0)\n",
    "create_rf_classifier_with_cv_and_weights(2, 1.5)\n",
    "create_rf_classifier_with_cv_and_weights(2, 2.0)\n",
    "\n",
    "create_rf_classifier_with_cv_and_weights(3, 1.0)\n",
    "create_rf_classifier_with_cv_and_weights(3, 1.5)\n",
    "create_rf_classifier_with_cv_and_weights(3, 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model/Metric</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADABoost</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost (neg/pos * 1.0)</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost (neg/pos * 2.0)</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost (neg/pos * 3.0)</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest (cv = 2)</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest (cv = 3)</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest (cv = 4)</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest (neg/pos * 1.0)</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random Forest (neg/pos * 2.0)</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Random Forest (neg/pos * 3.0)</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Random Forest (cv = 2) and (neg/pos * 1.0)</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Random Forest (cv = 2) and (neg/pos * 1.5)</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Random Forest (cv = 2) and (neg/pos * 2.0)</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Random Forest (cv = 3) and (neg/pos * 1.0)</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Random Forest (cv = 3) and (neg/pos * 1.5)</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Random Forest (cv = 3) and (neg/pos * 2.0)</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Model/Metric  Accuracy  Precision  Recall  \\\n",
       "0                          Logistic Regression      0.73       0.32    0.83   \n",
       "1                                          KNN      0.89       0.67    0.49   \n",
       "2                                     ADABoost      0.89       0.61    0.69   \n",
       "3                      XGBoost (neg/pos * 1.0)      0.92       0.70    0.83   \n",
       "4                      XGBoost (neg/pos * 2.0)      0.89       0.56    0.88   \n",
       "5                      XGBoost (neg/pos * 3.0)      0.85       0.49    0.91   \n",
       "6                                Random Forest      0.90       0.62    0.78   \n",
       "7                       Random Forest (cv = 2)      0.91       0.64    0.79   \n",
       "8                       Random Forest (cv = 3)      0.91       0.64    0.79   \n",
       "9                       Random Forest (cv = 4)      0.91       0.65    0.78   \n",
       "10               Random Forest (neg/pos * 1.0)      0.90       0.62    0.78   \n",
       "11               Random Forest (neg/pos * 2.0)      0.75       0.35    0.89   \n",
       "12               Random Forest (neg/pos * 3.0)      0.60       0.26    0.95   \n",
       "13  Random Forest (cv = 2) and (neg/pos * 1.0)      0.91       0.64    0.79   \n",
       "14  Random Forest (cv = 2) and (neg/pos * 1.5)      0.87       0.52    0.83   \n",
       "15  Random Forest (cv = 2) and (neg/pos * 2.0)      0.81       0.42    0.87   \n",
       "16  Random Forest (cv = 3) and (neg/pos * 1.0)      0.91       0.64    0.79   \n",
       "17  Random Forest (cv = 3) and (neg/pos * 1.5)      0.87       0.52    0.83   \n",
       "18  Random Forest (cv = 3) and (neg/pos * 2.0)      0.82       0.43    0.87   \n",
       "\n",
       "    F1-score   AUC  \n",
       "0       0.47  0.86  \n",
       "1       0.57  0.84  \n",
       "2       0.65  0.88  \n",
       "3       0.76  0.95  \n",
       "4       0.69  0.95  \n",
       "5       0.64  0.95  \n",
       "6       0.69  0.92  \n",
       "7       0.71  0.93  \n",
       "8       0.71  0.93  \n",
       "9       0.71  0.93  \n",
       "10      0.69  0.92  \n",
       "11      0.51  0.92  \n",
       "12      0.40  0.92  \n",
       "13      0.71  0.93  \n",
       "14      0.64  0.93  \n",
       "15      0.57  0.93  \n",
       "16      0.71  0.93  \n",
       "17      0.64  0.93  \n",
       "18      0.58  0.93  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print metrics df\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv('model_metrics.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
